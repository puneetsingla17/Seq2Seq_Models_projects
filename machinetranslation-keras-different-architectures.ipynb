{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['small_vocab_fr.txt', 'small_vocab_en.txt']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.models import Model,Sequential\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from keras.layers import GRU,Embedding,Bidirectional,InputLayer,Input,Dense,TimeDistributed,Activation,RepeatVector,Bidirectional\n",
    "import os\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "print(os.listdir(\"../input\"))\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../input/small_vocab_en.txt\") as f:\n",
    "    eng=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/small_vocab_fr.txt\") as f:\n",
    "    fr=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr=fr.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137861"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\ufeffnew jersey est parfois calme pendant l' automne , et il est neigeux en avril .\",\n",
       " 'les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .',\n",
       " 'california est généralement calme en mars , et il est généralement chaud en juin .',\n",
       " 'les états-unis est parfois légère en juin , et il fait froid en septembre .',\n",
       " 'votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new j'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng=eng.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new jersey is sometimes quiet during autumn , and it is snowy in april .',\n",
       " 'the united states is usually chilly during july , and it is usually freezing in november .',\n",
       " 'california is usually quiet during march , and it is usually hot in june .',\n",
       " 'the united states is sometimes mild during june , and it is cold in september .',\n",
       " 'your least liked fruit is the grape , but my least liked is the apple .']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137861"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new jersey is sometimes quiet during autumn , and it is snowy in april .',\n",
       " 'the united states is usually chilly during july , and it is usually freezing in november .',\n",
       " 'california is usually quiet during march , and it is usually hot in june .',\n",
       " 'the united states is sometimes mild during june , and it is cold in september .',\n",
       " 'your least liked fruit is the grape , but my least liked is the apple .',\n",
       " 'his favorite fruit is the orange , but my favorite is the grape .',\n",
       " 'paris is relaxing during december , but it is usually chilly in july .',\n",
       " 'new jersey is busy during spring , and it is never hot in march .',\n",
       " 'our least liked fruit is the lemon , but my least liked is the grape .',\n",
       " 'the united states is sometimes busy during january , and it is sometimes warm in november .']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "engdict=Counter([token for sent in eng for token in sent.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 205858),\n",
       " (',', 140897),\n",
       " ('.', 129039),\n",
       " ('in', 75525),\n",
       " ('it', 75137),\n",
       " ('during', 74933),\n",
       " ('the', 67628),\n",
       " ('but', 63987),\n",
       " ('and', 59850),\n",
       " ('sometimes', 37746),\n",
       " ('usually', 37507),\n",
       " ('never', 37500),\n",
       " ('least', 27564),\n",
       " ('favorite', 27371),\n",
       " ('fruit', 27105),\n",
       " ('most', 14934),\n",
       " ('loved', 13666),\n",
       " ('liked', 13546),\n",
       " ('new', 12197),\n",
       " ('paris', 11334),\n",
       " ('india', 11277),\n",
       " ('united', 11270),\n",
       " ('states', 11270),\n",
       " ('california', 11250),\n",
       " ('jersey', 11225),\n",
       " ('france', 11170),\n",
       " ('china', 10953),\n",
       " ('he', 10786),\n",
       " ('she', 10786),\n",
       " ('grapefruit', 10118)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engdict.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frdict=Counter(token for sent in fr for token in sent.split(\" \"))  # most common words are usually stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('est', 196809),\n",
       " ('.', 135619),\n",
       " (',', 123135),\n",
       " ('en', 105768),\n",
       " ('il', 84079),\n",
       " ('les', 65255),\n",
       " ('mais', 63987),\n",
       " ('et', 59851),\n",
       " ('la', 49861),\n",
       " ('parfois', 37746),\n",
       " ('jamais', 37215),\n",
       " ('le', 35306),\n",
       " (\"l'\", 32917),\n",
       " ('généralement', 31292),\n",
       " ('moins', 27557),\n",
       " ('au', 25738),\n",
       " ('aimé', 24842),\n",
       " ('fruit', 23626),\n",
       " ('préféré', 22886),\n",
       " ('agréable', 17751)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frdict.most_common(20) #Most Common words are usually the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocabsize=len(engdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_vocabsize=len(frdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_vocabsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vocabsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize words into indexes we use keras tokenizer\n",
    "engtokenizer=Tokenizer()\n",
    "engtokenizer.fit_on_texts(eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_token=engtokenizer.texts_to_sequences(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 23, 1, 8, 67, 4, 39, 7, 3, 1, 55, 2, 44],\n",
       " [5, 20, 21, 1, 9, 62, 4, 43, 7, 3, 1, 9, 51, 2, 45],\n",
       " [22, 1, 9, 67, 4, 38, 7, 3, 1, 9, 68, 2, 34],\n",
       " [5, 20, 21, 1, 8, 64, 4, 34, 7, 3, 1, 57, 2, 42],\n",
       " [29, 12, 16, 13, 1, 5, 82, 6, 30, 12, 16, 1, 5, 83]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_token[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "frtokenizer=Tokenizer()\n",
    "frtokenizer.fit_on_texts(fr)\n",
    "fr_token=frtokenizer.texts_to_sequences(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\ufeffnew jersey est parfois calme pendant l' automne , et il est neigeux en avril .\",\n",
       " 'les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .',\n",
       " 'california est généralement calme en mars , et il est généralement chaud en juin .',\n",
       " 'les états-unis est parfois légère en juin , et il fait froid en septembre .',\n",
       " 'votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[337, 34, 1, 8, 67, 37, 11, 24, 6, 3, 1, 112, 2, 50],\n",
       " [4, 32, 31, 1, 12, 19, 2, 49, 6, 3, 95, 69, 2, 51],\n",
       " [101, 1, 12, 67, 2, 45, 6, 3, 1, 12, 21, 2, 41],\n",
       " [4, 32, 31, 1, 8, 269, 2, 41, 6, 3, 103, 19, 2, 48],\n",
       " [40, 13, 14, 16, 1, 10, 82, 5, 39, 13, 14, 1, 7, 83]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_token[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ind=engtokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 1,\n",
       " 'in': 2,\n",
       " 'it': 3,\n",
       " 'during': 4,\n",
       " 'the': 5,\n",
       " 'but': 6,\n",
       " 'and': 7,\n",
       " 'sometimes': 8,\n",
       " 'usually': 9,\n",
       " 'never': 10,\n",
       " 'favorite': 11,\n",
       " 'least': 12,\n",
       " 'fruit': 13,\n",
       " 'most': 14,\n",
       " 'loved': 15,\n",
       " 'liked': 16,\n",
       " 'new': 17,\n",
       " 'paris': 18,\n",
       " 'india': 19,\n",
       " 'united': 20,\n",
       " 'states': 21,\n",
       " 'california': 22,\n",
       " 'jersey': 23,\n",
       " 'france': 24,\n",
       " 'china': 25,\n",
       " 'he': 26,\n",
       " 'she': 27,\n",
       " 'grapefruit': 28,\n",
       " 'your': 29,\n",
       " 'my': 30,\n",
       " 'his': 31,\n",
       " 'her': 32,\n",
       " 'fall': 33,\n",
       " 'june': 34,\n",
       " 'spring': 35,\n",
       " 'january': 36,\n",
       " 'winter': 37,\n",
       " 'march': 38,\n",
       " 'autumn': 39,\n",
       " 'may': 40,\n",
       " 'nice': 41,\n",
       " 'september': 42,\n",
       " 'july': 43,\n",
       " 'april': 44,\n",
       " 'november': 45,\n",
       " 'summer': 46,\n",
       " 'december': 47,\n",
       " 'february': 48,\n",
       " 'our': 49,\n",
       " 'their': 50,\n",
       " 'freezing': 51,\n",
       " 'pleasant': 52,\n",
       " 'beautiful': 53,\n",
       " 'october': 54,\n",
       " 'snowy': 55,\n",
       " 'warm': 56,\n",
       " 'cold': 57,\n",
       " 'wonderful': 58,\n",
       " 'dry': 59,\n",
       " 'busy': 60,\n",
       " 'august': 61,\n",
       " 'chilly': 62,\n",
       " 'rainy': 63,\n",
       " 'mild': 64,\n",
       " 'wet': 65,\n",
       " 'relaxing': 66,\n",
       " 'quiet': 67,\n",
       " 'hot': 68,\n",
       " 'dislikes': 69,\n",
       " 'likes': 70,\n",
       " 'limes': 71,\n",
       " 'lemons': 72,\n",
       " 'grapes': 73,\n",
       " 'mangoes': 74,\n",
       " 'apples': 75,\n",
       " 'peaches': 76,\n",
       " 'oranges': 77,\n",
       " 'pears': 78,\n",
       " 'strawberries': 79,\n",
       " 'bananas': 80,\n",
       " 'to': 81,\n",
       " 'grape': 82,\n",
       " 'apple': 83,\n",
       " 'orange': 84,\n",
       " 'lemon': 85,\n",
       " 'lime': 86,\n",
       " 'banana': 87,\n",
       " 'mango': 88,\n",
       " 'pear': 89,\n",
       " 'strawberry': 90,\n",
       " 'peach': 91,\n",
       " 'like': 92,\n",
       " 'dislike': 93,\n",
       " 'they': 94,\n",
       " 'that': 95,\n",
       " 'i': 96,\n",
       " 'we': 97,\n",
       " 'you': 98,\n",
       " 'animal': 99,\n",
       " 'a': 100,\n",
       " 'truck': 101,\n",
       " 'car': 102,\n",
       " 'automobile': 103,\n",
       " 'was': 104,\n",
       " 'next': 105,\n",
       " 'go': 106,\n",
       " 'driving': 107,\n",
       " 'visit': 108,\n",
       " 'little': 109,\n",
       " 'big': 110,\n",
       " 'old': 111,\n",
       " 'yellow': 112,\n",
       " 'red': 113,\n",
       " 'rusty': 114,\n",
       " 'blue': 115,\n",
       " 'white': 116,\n",
       " 'black': 117,\n",
       " 'green': 118,\n",
       " 'shiny': 119,\n",
       " 'are': 120,\n",
       " 'last': 121,\n",
       " 'feared': 122,\n",
       " 'animals': 123,\n",
       " 'this': 124,\n",
       " 'plan': 125,\n",
       " 'going': 126,\n",
       " 'saw': 127,\n",
       " 'disliked': 128,\n",
       " 'drives': 129,\n",
       " 'drove': 130,\n",
       " 'between': 131,\n",
       " 'translate': 132,\n",
       " 'plans': 133,\n",
       " 'were': 134,\n",
       " 'went': 135,\n",
       " 'might': 136,\n",
       " 'wanted': 137,\n",
       " 'thinks': 138,\n",
       " 'spanish': 139,\n",
       " 'portuguese': 140,\n",
       " 'chinese': 141,\n",
       " 'english': 142,\n",
       " 'french': 143,\n",
       " 'translating': 144,\n",
       " 'difficult': 145,\n",
       " 'fun': 146,\n",
       " 'easy': 147,\n",
       " 'wants': 148,\n",
       " 'think': 149,\n",
       " 'why': 150,\n",
       " \"it's\": 151,\n",
       " 'did': 152,\n",
       " 'cat': 153,\n",
       " 'shark': 154,\n",
       " 'bird': 155,\n",
       " 'mouse': 156,\n",
       " 'horse': 157,\n",
       " 'elephant': 158,\n",
       " 'dog': 159,\n",
       " 'monkey': 160,\n",
       " 'lion': 161,\n",
       " 'bear': 162,\n",
       " 'rabbit': 163,\n",
       " 'snake': 164,\n",
       " 'when': 165,\n",
       " 'want': 166,\n",
       " 'do': 167,\n",
       " 'how': 168,\n",
       " 'elephants': 169,\n",
       " 'horses': 170,\n",
       " 'dogs': 171,\n",
       " 'sharks': 172,\n",
       " 'snakes': 173,\n",
       " 'cats': 174,\n",
       " 'rabbits': 175,\n",
       " 'monkeys': 176,\n",
       " 'bears': 177,\n",
       " 'birds': 178,\n",
       " 'lions': 179,\n",
       " 'mice': 180,\n",
       " \"didn't\": 181,\n",
       " 'eiffel': 182,\n",
       " 'tower': 183,\n",
       " 'grocery': 184,\n",
       " 'store': 185,\n",
       " 'football': 186,\n",
       " 'field': 187,\n",
       " 'lake': 188,\n",
       " 'school': 189,\n",
       " 'would': 190,\n",
       " \"aren't\": 191,\n",
       " 'been': 192,\n",
       " 'weather': 193,\n",
       " 'does': 194,\n",
       " 'has': 195,\n",
       " \"isn't\": 196,\n",
       " 'am': 197,\n",
       " 'where': 198,\n",
       " 'have': 199}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_ind=frtokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'est': 1,\n",
       " 'en': 2,\n",
       " 'il': 3,\n",
       " 'les': 4,\n",
       " 'mais': 5,\n",
       " 'et': 6,\n",
       " 'la': 7,\n",
       " 'parfois': 8,\n",
       " 'jamais': 9,\n",
       " 'le': 10,\n",
       " \"l'\": 11,\n",
       " 'généralement': 12,\n",
       " 'moins': 13,\n",
       " 'aimé': 14,\n",
       " 'au': 15,\n",
       " 'fruit': 16,\n",
       " 'préféré': 17,\n",
       " 'agréable': 18,\n",
       " 'froid': 19,\n",
       " 'son': 20,\n",
       " 'chaud': 21,\n",
       " 'de': 22,\n",
       " 'plus': 23,\n",
       " 'automne': 24,\n",
       " 'mois': 25,\n",
       " 'à': 26,\n",
       " 'elle': 27,\n",
       " 'citrons': 28,\n",
       " 'paris': 29,\n",
       " 'inde': 30,\n",
       " 'unis': 31,\n",
       " 'états': 32,\n",
       " 'france': 33,\n",
       " 'jersey': 34,\n",
       " 'new': 35,\n",
       " 'chine': 36,\n",
       " 'pendant': 37,\n",
       " 'pamplemousse': 38,\n",
       " 'mon': 39,\n",
       " 'votre': 40,\n",
       " 'juin': 41,\n",
       " 'printemps': 42,\n",
       " 'janvier': 43,\n",
       " 'hiver': 44,\n",
       " 'mars': 45,\n",
       " 'été': 46,\n",
       " 'mai': 47,\n",
       " 'septembre': 48,\n",
       " 'juillet': 49,\n",
       " 'avril': 50,\n",
       " 'novembre': 51,\n",
       " 'décembre': 52,\n",
       " 'février': 53,\n",
       " 'octobre': 54,\n",
       " 'aime': 55,\n",
       " 'août': 56,\n",
       " 'merveilleux': 57,\n",
       " 'relaxant': 58,\n",
       " 'doux': 59,\n",
       " 'humide': 60,\n",
       " 'notre': 61,\n",
       " 'californie': 62,\n",
       " 'sec': 63,\n",
       " 'leur': 64,\n",
       " 'occupé': 65,\n",
       " 'pluvieux': 66,\n",
       " 'calme': 67,\n",
       " 'beau': 68,\n",
       " 'habituellement': 69,\n",
       " 'pommes': 70,\n",
       " 'pêches': 71,\n",
       " 'oranges': 72,\n",
       " 'poires': 73,\n",
       " 'fraises': 74,\n",
       " 'bananes': 75,\n",
       " 'verts': 76,\n",
       " 'raisins': 77,\n",
       " 'mangues': 78,\n",
       " \"d'\": 79,\n",
       " 'mangue': 80,\n",
       " 'gel': 81,\n",
       " 'raisin': 82,\n",
       " 'pomme': 83,\n",
       " \"l'orange\": 84,\n",
       " 'citron': 85,\n",
       " 'chaux': 86,\n",
       " 'banane': 87,\n",
       " 'poire': 88,\n",
       " 'fraise': 89,\n",
       " 'pêche': 90,\n",
       " 'pas': 91,\n",
       " 'enneigée': 92,\n",
       " 'favori': 93,\n",
       " 'déteste': 94,\n",
       " 'gèle': 95,\n",
       " 'fruits': 96,\n",
       " 'voiture': 97,\n",
       " \"l'automne\": 98,\n",
       " 'ils': 99,\n",
       " \"n'aime\": 100,\n",
       " 'california': 101,\n",
       " 'neige': 102,\n",
       " 'fait': 103,\n",
       " 'belle': 104,\n",
       " 'ne': 105,\n",
       " 'vous': 106,\n",
       " 'nous': 107,\n",
       " 'des': 108,\n",
       " 'animal': 109,\n",
       " 'camion': 110,\n",
       " 'cours': 111,\n",
       " 'neigeux': 112,\n",
       " 'conduit': 113,\n",
       " 'prochain': 114,\n",
       " 'ce': 115,\n",
       " 'je': 116,\n",
       " 'tranquille': 117,\n",
       " 'a': 118,\n",
       " 'cher': 119,\n",
       " 'une': 120,\n",
       " 'cette': 121,\n",
       " 'était': 122,\n",
       " 'aller': 123,\n",
       " 'aiment': 124,\n",
       " 'chaude': 125,\n",
       " 'aimons': 126,\n",
       " \"n'aiment\": 127,\n",
       " \"n'aimez\": 128,\n",
       " 'leurs': 129,\n",
       " 'aimez': 130,\n",
       " 'sont': 131,\n",
       " 'détestons': 132,\n",
       " 'jaune': 133,\n",
       " 'rouge': 134,\n",
       " \"j'aime\": 135,\n",
       " 'visiter': 136,\n",
       " 'sèche': 137,\n",
       " 'occupée': 138,\n",
       " 'frisquet': 139,\n",
       " 'préférée': 140,\n",
       " 'animaux': 141,\n",
       " 'dernier': 142,\n",
       " 'aimait': 143,\n",
       " 'un': 144,\n",
       " 'conduisait': 145,\n",
       " 'que': 146,\n",
       " 'nouvelle': 147,\n",
       " 'vieille': 148,\n",
       " 'vu': 149,\n",
       " 'verte': 150,\n",
       " 'petite': 151,\n",
       " 'nos': 152,\n",
       " 'noire': 153,\n",
       " 'brillant': 154,\n",
       " 'blanche': 155,\n",
       " 'redouté': 156,\n",
       " 'pleut': 157,\n",
       " \"n'aimait\": 158,\n",
       " 'pamplemousses': 159,\n",
       " 'pense': 160,\n",
       " 'entre': 161,\n",
       " 'bleue': 162,\n",
       " 'nouveau': 163,\n",
       " 'traduire': 164,\n",
       " 'rouillée': 165,\n",
       " 'bleu': 166,\n",
       " 'se': 167,\n",
       " 'grande': 168,\n",
       " 'rouillé': 169,\n",
       " 'ses': 170,\n",
       " \"qu'il\": 171,\n",
       " 'blanc': 172,\n",
       " 'aux': 173,\n",
       " 'brillante': 174,\n",
       " 'préférés': 175,\n",
       " 'noir': 176,\n",
       " 'pluies': 177,\n",
       " 'envisage': 178,\n",
       " 'étaient': 179,\n",
       " 'va': 180,\n",
       " 'rendre': 181,\n",
       " 'vert': 182,\n",
       " 'vieux': 183,\n",
       " 'petit': 184,\n",
       " 'espagnol': 185,\n",
       " 'portugais': 186,\n",
       " 'chinois': 187,\n",
       " 'anglais': 188,\n",
       " 'français': 189,\n",
       " 'glaciales': 190,\n",
       " 'mes': 191,\n",
       " 'cet': 192,\n",
       " 'automobile': 193,\n",
       " 'traduction': 194,\n",
       " 'mouillé': 195,\n",
       " 'difficile': 196,\n",
       " 'amusant': 197,\n",
       " 'facile': 198,\n",
       " 'comme': 199,\n",
       " 'gros': 200,\n",
       " 'souris': 201,\n",
       " 'pourrait': 202,\n",
       " 'voulait': 203,\n",
       " 'veut': 204,\n",
       " 'pourquoi': 205,\n",
       " 'aimés': 206,\n",
       " 'prévois': 207,\n",
       " 'prévoyons': 208,\n",
       " 'vos': 209,\n",
       " 'intention': 210,\n",
       " 'clémentes': 211,\n",
       " 'ont': 212,\n",
       " 'chat': 213,\n",
       " 'requin': 214,\n",
       " 'cheval': 215,\n",
       " 'chien': 216,\n",
       " 'singe': 217,\n",
       " 'lion': 218,\n",
       " 'ours': 219,\n",
       " 'lapin': 220,\n",
       " 'serpent': 221,\n",
       " 'redoutés': 222,\n",
       " 'allé': 223,\n",
       " 'grosse': 224,\n",
       " 'pluie': 225,\n",
       " 'trop': 226,\n",
       " 'monde': 227,\n",
       " 'maillot': 228,\n",
       " 'vont': 229,\n",
       " 'volant': 230,\n",
       " 'avez': 231,\n",
       " 'i': 232,\n",
       " 'allés': 233,\n",
       " 'allée': 234,\n",
       " 'quand': 235,\n",
       " 'oiseau': 236,\n",
       " 'éléphant': 237,\n",
       " 'pourraient': 238,\n",
       " 'voulaient': 239,\n",
       " 'veulent': 240,\n",
       " 'détendre': 241,\n",
       " 'aimée': 242,\n",
       " 'magnifique': 243,\n",
       " \"l'automobile\": 244,\n",
       " \"n'aimons\": 245,\n",
       " 'gelé': 246,\n",
       " 'détestait': 247,\n",
       " 'grand': 248,\n",
       " 'bien': 249,\n",
       " 'vers': 250,\n",
       " 'prévoient': 251,\n",
       " 'prévoit': 252,\n",
       " 'lui': 253,\n",
       " 'visite': 254,\n",
       " 'comment': 255,\n",
       " 'éléphants': 256,\n",
       " 'chevaux': 257,\n",
       " 'chiens': 258,\n",
       " \"l'éléphant\": 259,\n",
       " \"l'oiseau\": 260,\n",
       " 'requins': 261,\n",
       " \"l'ours\": 262,\n",
       " 'serpents': 263,\n",
       " 'chats': 264,\n",
       " 'lapins': 265,\n",
       " 'singes': 266,\n",
       " 'oiseaux': 267,\n",
       " 'lions': 268,\n",
       " 'légère': 269,\n",
       " 'cépage': 270,\n",
       " 'pensez': 271,\n",
       " 'tour': 272,\n",
       " 'eiffel': 273,\n",
       " \"l'épicerie\": 274,\n",
       " 'terrain': 275,\n",
       " 'football': 276,\n",
       " 'lac': 277,\n",
       " \"l'école\": 278,\n",
       " \"l'animal\": 279,\n",
       " \"n'est\": 280,\n",
       " 'allons': 281,\n",
       " 'allez': 282,\n",
       " 'peu': 283,\n",
       " 'pousse': 284,\n",
       " 'du': 285,\n",
       " 'temps': 286,\n",
       " 'at': 287,\n",
       " 'rouille': 288,\n",
       " 'sur': 289,\n",
       " \"qu'elle\": 290,\n",
       " 'petites': 291,\n",
       " 'dernière': 292,\n",
       " 'êtes': 293,\n",
       " 'vais': 294,\n",
       " 'voudrait': 295,\n",
       " 'proches': 296,\n",
       " 'frais': 297,\n",
       " 'manguiers': 298,\n",
       " 'avons': 299,\n",
       " 't': 300,\n",
       " 'porcelaine': 301,\n",
       " 'détestez': 302,\n",
       " \"c'est\": 303,\n",
       " 'grandes': 304,\n",
       " 'préférées': 305,\n",
       " 'douce': 306,\n",
       " 'durant': 307,\n",
       " 'congélation': 308,\n",
       " 'plaît': 309,\n",
       " 'où': 310,\n",
       " 'dans': 311,\n",
       " 'voulez': 312,\n",
       " 'aimeraient': 313,\n",
       " \"n'a\": 314,\n",
       " 'petits': 315,\n",
       " 'grands': 316,\n",
       " 'limes': 317,\n",
       " 'envisagent': 318,\n",
       " 'grosses': 319,\n",
       " 'bénigne': 320,\n",
       " 'mouillée': 321,\n",
       " 'enneigé': 322,\n",
       " 'moindres': 323,\n",
       " 'conduite': 324,\n",
       " 'gelés': 325,\n",
       " 'tout': 326,\n",
       " 'etats': 327,\n",
       " \"n'êtes\": 328,\n",
       " 'vit': 329,\n",
       " 'ressort': 330,\n",
       " 'détend': 331,\n",
       " 'redoutée': 332,\n",
       " 'tu': 333,\n",
       " 'qui': 334,\n",
       " 'traduis': 335,\n",
       " 'apprécié': 336,\n",
       " '\\ufeffnew': 337,\n",
       " 'allions': 338,\n",
       " 'trouvé': 339,\n",
       " 'as': 340,\n",
       " 'faire': 341,\n",
       " 'favoris': 342,\n",
       " 'souvent': 343,\n",
       " 'es': 344,\n",
       " 'moteur': 345}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_token_pad=pad_sequences(eng_token,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_token_pad=pad_sequences(fr_token,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 23, 1, 8, 67, 4, 39, 7, 3, 1, 55, 2, 44],\n",
       " [5, 20, 21, 1, 9, 62, 4, 43, 7, 3, 1, 9, 51, 2, 45],\n",
       " [22, 1, 9, 67, 4, 38, 7, 3, 1, 9, 68, 2, 34],\n",
       " [5, 20, 21, 1, 8, 64, 4, 34, 7, 3, 1, 57, 2, 42],\n",
       " [29, 12, 16, 13, 1, 5, 82, 6, 30, 12, 16, 1, 5, 83]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_token[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 15)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_token_pad[:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 is max english length size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 15)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_token_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 21)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_token_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21 is max fr token size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_token_pad=eng_token_pad.reshape(*eng_token_pad.shape,1)\n",
    "fr_token_pad=fr_token_pad.reshape(*fr_token_pad.shape,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 15, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_token_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_w=frtokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_w[0]='<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng_length=eng_token_pad.shape[1]\n",
    "max_fr_length=fr_token_pad.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_eng_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_fr_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we Implement Four Different Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "inp=Input(shape=[21,1])\n",
    "x=GRU(64,return_sequences=True)(inp)\n",
    "logits=TimeDistributed(Dense(fr_vocabsize))(x)\n",
    "model=Model(inp,Activation('softmax')(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 23, 1, 8, 67, 4, 39, 7, 3, 1, 55, 2, 44],\n",
       " [5, 20, 21, 1, 9, 62, 4, 43, 7, 3, 1, 9, 51, 2, 45],\n",
       " [22, 1, 9, 67, 4, 38, 7, 3, 1, 9, 68, 2, 34],\n",
       " [5, 20, 21, 1, 8, 64, 4, 34, 7, 3, 1, 57, 2, 42],\n",
       " [29, 12, 16, 13, 1, 5, 82, 6, 30, 12, 16, 1, 5, 83]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_token[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x=pad_sequences(eng_token,maxlen=max_fr_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x=tmp_x.reshape((-1,21,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=sparse_categorical_crossentropy,optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 21, 1)             0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 21, 64)            12672     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 21, 357)           23205     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 21, 357)           0         \n",
      "=================================================================\n",
      "Total params: 35,877\n",
      "Trainable params: 35,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 21, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_token_pad.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jovianlin.io/cat-crossentropy-vs-sparse-cat-crossentropy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 21, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 21, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_token_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/30\n",
      "110288/110288 [==============================] - 7s 59us/step - loss: 3.5216 - val_loss: 2.5643\n",
      "Epoch 2/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 2.4506 - val_loss: 2.3328\n",
      "Epoch 3/30\n",
      "110288/110288 [==============================] - 4s 40us/step - loss: 2.2141 - val_loss: 2.0862\n",
      "Epoch 4/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.9708 - val_loss: 1.8655\n",
      "Epoch 5/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.7952 - val_loss: 1.7350\n",
      "Epoch 6/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.6933 - val_loss: 1.6549\n",
      "Epoch 7/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.6240 - val_loss: 1.5932\n",
      "Epoch 8/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.5668 - val_loss: 1.5404\n",
      "Epoch 9/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.5181 - val_loss: 1.4957\n",
      "Epoch 10/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.4757 - val_loss: 1.4561\n",
      "Epoch 11/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.4377 - val_loss: 1.4205\n",
      "Epoch 12/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.4036 - val_loss: 1.3879\n",
      "Epoch 13/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.3737 - val_loss: 1.3601\n",
      "Epoch 14/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.3479 - val_loss: 1.3360\n",
      "Epoch 15/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.3254 - val_loss: 1.3144\n",
      "Epoch 16/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.3055 - val_loss: 1.2966\n",
      "Epoch 17/30\n",
      "110288/110288 [==============================] - 4s 40us/step - loss: 1.2876 - val_loss: 1.2789\n",
      "Epoch 18/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.2714 - val_loss: 1.2635\n",
      "Epoch 19/30\n",
      "110288/110288 [==============================] - 4s 40us/step - loss: 1.2566 - val_loss: 1.2494\n",
      "Epoch 20/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.2431 - val_loss: 1.2357\n",
      "Epoch 21/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.2304 - val_loss: 1.2234\n",
      "Epoch 22/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.2184 - val_loss: 1.2118\n",
      "Epoch 23/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.2076 - val_loss: 1.2012\n",
      "Epoch 24/30\n",
      "110288/110288 [==============================] - 4s 40us/step - loss: 1.1972 - val_loss: 1.1909\n",
      "Epoch 25/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.1870 - val_loss: 1.1810\n",
      "Epoch 26/30\n",
      "110288/110288 [==============================] - 4s 40us/step - loss: 1.1771 - val_loss: 1.1720\n",
      "Epoch 27/30\n",
      "110288/110288 [==============================] - 4s 40us/step - loss: 1.1680 - val_loss: 1.1635\n",
      "Epoch 28/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.1590 - val_loss: 1.1532\n",
      "Epoch 29/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.1503 - val_loss: 1.1449\n",
      "Epoch 30/30\n",
      "110288/110288 [==============================] - 4s 39us/step - loss: 1.1419 - val_loss: 1.1367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe58435b5c0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tmp_x,fr_token_pad,batch_size=1024,epochs=30,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=[\"i am very quiet during spring and autumn\"]\n",
    "\n",
    "text1=engtokenizer.texts_to_sequences(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pad_sequences(text1,maxlen=max_fr_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.reshape((-1,21,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_of_a=model.predict(a)\n",
    "pred=np.argmax(pred_of_a,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ils vous les les et et et et <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([ind_w[i] for i in pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99, 106,   4,   4,   6,   6,   6,   6,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(tmp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 21, 357)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.argmax(pred,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pred.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2895081, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=fr_token_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=m.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(pred,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6570924958576289"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc # so we are getting 61% accuracy with 100 training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_fr_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(InputLayer((21,)))\n",
    "model.add(Embedding(eng_vocabsize,64,input_length=max_fr_length))\n",
    "model.add(GRU(64,return_sequences=True,activation='tanh'))\n",
    "model.add(TimeDistributed(Dense(fr_vocabsize,activation='softmax')))\n",
    "model.compile(loss=sparse_categorical_crossentropy,optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 21, 64)            14592     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 21, 64)            24768     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 21, 357)           23205     \n",
      "=================================================================\n",
      "Total params: 62,565\n",
      "Trainable params: 62,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x=tmp_x.reshape((-1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/30\n",
      "110288/110288 [==============================] - 5s 49us/step - loss: 3.7871 - val_loss: 2.9764\n",
      "Epoch 2/30\n",
      "110288/110288 [==============================] - 5s 41us/step - loss: 2.6719 - val_loss: 2.3356\n",
      "Epoch 3/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 1.9505 - val_loss: 1.6214\n",
      "Epoch 4/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 1.4182 - val_loss: 1.2434\n",
      "Epoch 5/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 1.1255 - val_loss: 1.0209\n",
      "Epoch 6/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.9452 - val_loss: 0.8752\n",
      "Epoch 7/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.8216 - val_loss: 0.7692\n",
      "Epoch 8/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.7316 - val_loss: 0.6915\n",
      "Epoch 9/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.6620 - val_loss: 0.6306\n",
      "Epoch 10/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.6067 - val_loss: 0.5845\n",
      "Epoch 11/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.5618 - val_loss: 0.5403\n",
      "Epoch 12/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.5255 - val_loss: 0.5105\n",
      "Epoch 13/30\n",
      "110288/110288 [==============================] - 5s 41us/step - loss: 0.4962 - val_loss: 0.4834\n",
      "Epoch 14/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.4696 - val_loss: 0.4616\n",
      "Epoch 15/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.4485 - val_loss: 0.4407\n",
      "Epoch 16/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.4287 - val_loss: 0.4225\n",
      "Epoch 17/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.4119 - val_loss: 0.4065\n",
      "Epoch 18/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3971 - val_loss: 0.3926\n",
      "Epoch 19/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3833 - val_loss: 0.3796\n",
      "Epoch 20/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3715 - val_loss: 0.3733\n",
      "Epoch 21/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3617 - val_loss: 0.3581\n",
      "Epoch 22/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3506 - val_loss: 0.3490\n",
      "Epoch 23/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3423 - val_loss: 0.3384\n",
      "Epoch 24/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3332 - val_loss: 0.3340\n",
      "Epoch 25/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3270 - val_loss: 0.3258\n",
      "Epoch 26/30\n",
      "110288/110288 [==============================] - 5s 41us/step - loss: 0.3197 - val_loss: 0.3186\n",
      "Epoch 27/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3136 - val_loss: 0.3126\n",
      "Epoch 28/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3071 - val_loss: 0.3082\n",
      "Epoch 29/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.3017 - val_loss: 0.3041\n",
      "Epoch 30/30\n",
      "110288/110288 [==============================] - 5s 42us/step - loss: 0.2972 - val_loss: 0.3062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe14f403a58>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tmp_x,fr_token_pad,batch_size=1024,epochs=30,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it out\n",
    "text1=[\"i am very quiet during spring and autumn\"]\n",
    "text1=engtokenizer.texts_to_sequences(text1)\n",
    "a=pad_sequences(text1,maxlen=max_fr_length,padding='post')\n",
    "a=a.reshape((-1,21))\n",
    "pred_of_a=model.predict(a)\n",
    "pred=np.argmax(pred_of_a,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je je je calme calme tranquille je calme <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([ind_w[i] for i in pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(tmp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.argmax(pred,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pred.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_token_pad1=fr_token_pad.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(pred,fr_token_pad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9071393857373938"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 3**\n",
    "\n",
    "**Bidirectional GRU Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(InputLayer((21,)))\n",
    "model.add(Embedding(eng_vocabsize,64,input_length=max_fr_length))\n",
    "model.add(Bidirectional(GRU(64,return_sequences=True,activation='tanh')))\n",
    "model.add(TimeDistributed(Dense(fr_vocabsize,activation='softmax')))\n",
    "model.compile(loss=sparse_categorical_crossentropy,optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 21, 64)            14592     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 21, 128)           49536     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 21, 357)           46053     \n",
      "=================================================================\n",
      "Total params: 110,181\n",
      "Trainable params: 110,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden states of GRU are concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/30\n",
      "110288/110288 [==============================] - 10s 89us/step - loss: 3.4524 - val_loss: 2.5207\n",
      "Epoch 2/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 2.2622 - val_loss: 1.8437\n",
      "Epoch 3/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.5126 - val_loss: 1.2588\n",
      "Epoch 4/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.1093 - val_loss: 0.9850\n",
      "Epoch 5/30\n",
      "110288/110288 [==============================] - 9s 78us/step - loss: 0.9000 - val_loss: 0.8208\n",
      "Epoch 6/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.7609 - val_loss: 0.7022\n",
      "Epoch 7/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.6551 - val_loss: 0.6098\n",
      "Epoch 8/30\n",
      "110288/110288 [==============================] - 8s 77us/step - loss: 0.5708 - val_loss: 0.5341\n",
      "Epoch 9/30\n",
      "110288/110288 [==============================] - 8s 77us/step - loss: 0.5049 - val_loss: 0.4773\n",
      "Epoch 10/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.4541 - val_loss: 0.4318\n",
      "Epoch 11/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.4124 - val_loss: 0.3951\n",
      "Epoch 12/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.3778 - val_loss: 0.3662\n",
      "Epoch 13/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.3492 - val_loss: 0.3395\n",
      "Epoch 14/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.3264 - val_loss: 0.3223\n",
      "Epoch 15/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.3064 - val_loss: 0.3003\n",
      "Epoch 16/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.2877 - val_loss: 0.2868\n",
      "Epoch 17/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.2734 - val_loss: 0.2700\n",
      "Epoch 18/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.2596 - val_loss: 0.2564\n",
      "Epoch 19/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.2485 - val_loss: 0.2463\n",
      "Epoch 20/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.2373 - val_loss: 0.2379\n",
      "Epoch 21/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.2271 - val_loss: 0.2273\n",
      "Epoch 22/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.2182 - val_loss: 0.2191\n",
      "Epoch 23/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.2095 - val_loss: 0.2130\n",
      "Epoch 24/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.2020 - val_loss: 0.2059\n",
      "Epoch 25/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.1954 - val_loss: 0.1976\n",
      "Epoch 26/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.1886 - val_loss: 0.1913\n",
      "Epoch 27/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.1822 - val_loss: 0.1860\n",
      "Epoch 28/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.1762 - val_loss: 0.1811\n",
      "Epoch 29/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 0.1710 - val_loss: 0.1790\n",
      "Epoch 30/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 0.1658 - val_loss: 0.1726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe14f4038d0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tmp_x,fr_token_pad,batch_size=1024,epochs=30,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it out\n",
    "text1=[\"i am very quiet during spring and autumn\"]\n",
    "text1=engtokenizer.texts_to_sequences(text1)\n",
    "a=pad_sequences(text1,maxlen=max_fr_length,padding='post')\n",
    "a=a.reshape((-1,21))\n",
    "pred_of_a=model.predict(a)\n",
    "pred=np.argmax(pred_of_a,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"j'aime il calme calme au printemps et <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([ind_w[i] for i in pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(tmp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.argmax(pred,axis=-1)\n",
    "pred=pred.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(pred,fr_token_pad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534382630399633"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reason for Using GRU  instead of LSTM because Sentences are short .GRU is fast as compared to lstm and less complicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 4**\n",
    "**Seq2Seq Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(GRU(128,input_shape=(21,1)))\n",
    "model.add(RepeatVector(max_fr_length))\n",
    "model.add(GRU(128,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(fr_vocabsize,activation='softmax')))\n",
    "model.compile(loss=sparse_categorical_crossentropy,optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 128)               49920     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 21, 128)           98688     \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 21, 357)           46053     \n",
      "=================================================================\n",
      "Total params: 194,661\n",
      "Trainable params: 194,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is different way of implementing Encoder Decoder as in tensorflow\n",
    "# in tensorflow . last encoder hidden state is given as initial hidden state of \n",
    "# decoder and predictions are made\n",
    "# here iniital state is zero for decoder but last hidden state of decoder \n",
    "# is given as input for in form of timesteps for decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x=tmp_x.reshape((-1,21,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/30\n",
      "110288/110288 [==============================] - 10s 91us/step - loss: 3.0970 - val_loss: 2.4964\n",
      "Epoch 2/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 2.3625 - val_loss: 2.2523\n",
      "Epoch 3/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 2.1834 - val_loss: 2.1157\n",
      "Epoch 4/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 2.0269 - val_loss: 1.8955\n",
      "Epoch 5/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.7829 - val_loss: 1.7033\n",
      "Epoch 6/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.6488 - val_loss: 1.5984\n",
      "Epoch 7/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.5652 - val_loss: 1.5243\n",
      "Epoch 8/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.4959 - val_loss: 1.4646\n",
      "Epoch 9/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.4425 - val_loss: 1.4167\n",
      "Epoch 10/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.3998 - val_loss: 1.3886\n",
      "Epoch 11/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.3678 - val_loss: 1.3541\n",
      "Epoch 12/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.3484 - val_loss: 1.3350\n",
      "Epoch 13/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.3250 - val_loss: 1.3131\n",
      "Epoch 14/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.3099 - val_loss: 1.3015\n",
      "Epoch 15/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.3036 - val_loss: 1.2913\n",
      "Epoch 16/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.2871 - val_loss: 1.2822\n",
      "Epoch 17/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.2781 - val_loss: 1.2726\n",
      "Epoch 18/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.2679 - val_loss: 1.2618\n",
      "Epoch 19/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.2579 - val_loss: 1.2524\n",
      "Epoch 20/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.2460 - val_loss: 1.2404\n",
      "Epoch 21/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.2323 - val_loss: 1.2193\n",
      "Epoch 22/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.2168 - val_loss: 1.2065\n",
      "Epoch 23/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.2026 - val_loss: 1.1946\n",
      "Epoch 24/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.1841 - val_loss: 1.1774\n",
      "Epoch 25/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.1630 - val_loss: 1.1494\n",
      "Epoch 26/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.1443 - val_loss: 1.1213\n",
      "Epoch 27/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.1400 - val_loss: 1.1390\n",
      "Epoch 28/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.1116 - val_loss: 1.1871\n",
      "Epoch 29/30\n",
      "110288/110288 [==============================] - 8s 76us/step - loss: 1.1080 - val_loss: 1.1927\n",
      "Epoch 30/30\n",
      "110288/110288 [==============================] - 8s 75us/step - loss: 1.0834 - val_loss: 1.0513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe14cdedac8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tmp_x,fr_token_pad,batch_size=1024,epochs=30,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it out\n",
    "text1=[\"i am very quiet during spring and autumn\"]\n",
    "text1=engtokenizer.texts_to_sequences(text1)\n",
    "a=pad_sequences(text1,maxlen=max_fr_length,padding='post')\n",
    "a=a.reshape((-1,21,1))\n",
    "pred_of_a=model.predict(a)\n",
    "pred=np.argmax(pred_of_a,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ils aiment le visiter le citrons et <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([ind_w[i] for i in pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(tmp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.argmax(pred,axis=-1)\n",
    "pred=pred.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(pred,fr_token_pad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6828258000380646"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 5  Seq2seq with Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(InputLayer((21,)))\n",
    "model.add(Embedding(eng_vocabsize,32,input_length=21))\n",
    "model.add(Bidirectional(GRU(256,activation='tanh')))\n",
    "model.add(RepeatVector(max_fr_length))\n",
    "model.add(GRU(256,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(fr_vocabsize,activation='softmax')))\n",
    "model.compile(loss=sparse_categorical_crossentropy,optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 21, 32)            7296      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               443904    \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 21, 256)           590592    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 21, 357)           91749     \n",
      "=================================================================\n",
      "Total params: 1,133,541\n",
      "Trainable params: 1,133,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x=tmp_x.reshape((-1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/30\n",
      "110288/110288 [==============================] - 15s 138us/step - loss: 3.1043 - val_loss: 2.6636\n",
      "Epoch 2/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 2.2545 - val_loss: 1.9271\n",
      "Epoch 3/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 1.7347 - val_loss: 1.5842\n",
      "Epoch 4/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 1.4869 - val_loss: 1.3944\n",
      "Epoch 5/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 1.3414 - val_loss: 1.2799\n",
      "Epoch 6/30\n",
      "110288/110288 [==============================] - 13s 117us/step - loss: 1.2311 - val_loss: 1.1639\n",
      "Epoch 7/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 1.1057 - val_loss: 1.0478\n",
      "Epoch 8/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 1.0191 - val_loss: 0.9701\n",
      "Epoch 9/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.9479 - val_loss: 0.9395\n",
      "Epoch 10/30\n",
      "110288/110288 [==============================] - 13s 117us/step - loss: 0.8912 - val_loss: 0.8698\n",
      "Epoch 11/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.8440 - val_loss: 0.8178\n",
      "Epoch 12/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.8020 - val_loss: 0.7825\n",
      "Epoch 13/30\n",
      "110288/110288 [==============================] - 13s 117us/step - loss: 0.7564 - val_loss: 0.7387\n",
      "Epoch 14/30\n",
      "110288/110288 [==============================] - 13s 117us/step - loss: 0.7179 - val_loss: 0.6962\n",
      "Epoch 15/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.6768 - val_loss: 0.6563\n",
      "Epoch 16/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.6370 - val_loss: 0.6288\n",
      "Epoch 17/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.5978 - val_loss: 0.5791\n",
      "Epoch 18/30\n",
      "110288/110288 [==============================] - 13s 117us/step - loss: 0.5618 - val_loss: 0.5481\n",
      "Epoch 19/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.5238 - val_loss: 0.5134\n",
      "Epoch 20/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.4896 - val_loss: 0.4722\n",
      "Epoch 21/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.4524 - val_loss: 0.4382\n",
      "Epoch 22/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.4233 - val_loss: 0.4094\n",
      "Epoch 23/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.3904 - val_loss: 0.3842\n",
      "Epoch 24/30\n",
      "110288/110288 [==============================] - 13s 119us/step - loss: 0.3618 - val_loss: 0.3685\n",
      "Epoch 25/30\n",
      "110288/110288 [==============================] - 13s 115us/step - loss: 0.3352 - val_loss: 0.3258\n",
      "Epoch 26/30\n",
      "110288/110288 [==============================] - 13s 115us/step - loss: 0.3065 - val_loss: 0.3114\n",
      "Epoch 27/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.2846 - val_loss: 0.2837\n",
      "Epoch 28/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.2669 - val_loss: 0.2605\n",
      "Epoch 29/30\n",
      "110288/110288 [==============================] - 13s 116us/step - loss: 0.2384 - val_loss: 0.2460\n",
      "Epoch 30/30\n",
      "110288/110288 [==============================] - 13s 115us/step - loss: 0.2202 - val_loss: 0.2209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe14bad04a8>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tmp_x,fr_token_pad,batch_size=1024,epochs=30,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(tmp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.argmax(pred,axis=-1)\n",
    "pred=pred.reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(pred,fr_token_pad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440893018191892"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=[\"i liked lemon and grape\"]\n",
    "text1=engtokenizer.texts_to_sequences(text1)\n",
    "a=pad_sequences(text1,maxlen=max_fr_length,padding='post')\n",
    "a=a.reshape((-1,21))\n",
    "pred_of_a=model.predict(a)\n",
    "pred=np.argmax(pred_of_a,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"j'aime le pamplemousse pamplemousse pamplemousse <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([ind_w[i] for i in pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
